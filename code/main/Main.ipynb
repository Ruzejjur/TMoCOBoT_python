{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "# Task: Describe packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting working directory\n",
    "working_directory = '/Users/ruzejjur/Github/TMoCOBoT_python'\n",
    "os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding scripts\n",
    "# Add the directory containing the script to sys.path\n",
    "script_path = os.path.abspath(os.path.join(working_directory, 'Code', 'auxiliary'))\n",
    "sys.path.append(script_path)\n",
    "\n",
    "# Importing auxiliary functions script\n",
    "\n",
    "import auxiliary  # noqa: E402\n",
    "\n",
    "# Reload the module to ensure changes are reflected\n",
    "importlib.reload(auxiliary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated examples\n",
    "\n",
    "To simplify the analysis, specific parameters are defined for the experts, which include the following:\n",
    "\n",
    " - 10 experts for each brand. \n",
    " - 3 mobile brands.\n",
    " - 3 features.\n",
    " - 6 score values.\n",
    "\n",
    "These parameters have been deliberately chosen to configure the system and demonstrate the functionality of our proposed solution.\n",
    "\n",
    "The parameters associated with the primary modeler are as follows:\n",
    "\n",
    " - The preference score $r_{I,n}$ = 4 for all features.\n",
    " - The primary modeler's brand $P_{I}(B)$ preference follows a uniform distribution.\n",
    " - The primary modeler's opinion on brands $b\\in{B}$ is established in the experimental setup.\n",
    " - The primary modeler's certainty $c_{I,b,n} \\in \\langle 0, 1 \\rangle$ is established in the experimental setup.\n",
    " - The primary modeler's trust $t_{I,E_{i}} \\in \\langle 0, 1 \\rangle$ is established in the experimental setup.\n",
    "\n",
    "The preference score is set for simplicity, eliminating one hyper-parameter to tune. \n",
    "The primary modeler's brand preference $P_{I}(B)$ is configured to ensure that the choice of the brand $b\\in{B}$ is not influenced by the primary modeler's bias.\n",
    "\n",
    "The objective is to design experiments in such a way that the brand selection process can be inferred from the setup of the experts.\n",
    "\n",
    "In the following five examples, the primary modeler's opinions are presented in the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modeler's opinion\n",
    "primary_modeler_scores = [\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "]\n",
    "\n",
    "# Creating a DataFrame with the given data\n",
    "primary_modeler_scores_df = pd.DataFrame(\n",
    "    primary_modeler_scores,\n",
    "    index=[\"Samsung\", \"iPhone\", \"Xiaomi\"],\n",
    "    columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\"]\n",
    ")\n",
    "\n",
    "print(primary_modeler_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary modeler's opinion on brands is as follows: **iPhone > Samsung > Xiaomi**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion Merging and Preference Subsetting\n",
    "\n",
    "The aim of this section is to illustrate the influence of expert opinions on the primary modeler's brand preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "The experts are configured to prefer the brands in the following order:\n",
    "\n",
    " **Samsung > iPhone  > Xiaomi**.\n",
    "\n",
    "The Samsung is slightly more preferred than iPhone, this is set up for later demonstration of the trust value $t_{I,E_{i}}$ in 'Inclusion of trust' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "\n",
    "apply_certainty = False\n",
    "\n",
    "# Setting up the number of responders for each brand so that the opinion\n",
    "# certainty can be applied as many times as the responders responded\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Converting the primary modelers scores to a DataFrame for better readability\n",
    "primary_modeler_scores_df = pd.DataFrame(\n",
    "    primary_modeler_scores,\n",
    "    index=[\"Samsung\", \"iPhone\", \"Xiaomi\"],\n",
    "    columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\"]\n",
    ")\n",
    "\n",
    "print(\"The Primary Modeler's Scores:\")\n",
    "print(primary_modeler_scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opinion's of individual experts $E_{i}$ for each brand $b\\in{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [4, 3, 4], [5, 3, 5], [5, 6, 5], [6, 5, 3], [6, 6, 6], \n",
    "    [5, 6, 5], [6, 6, 5], [6, 3, 4], [4, 5, 4], [6, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Creating DataFrames for each brand\n",
    "samsung_expert_opinions_df = pd.DataFrame(\n",
    "    samsung_expert_opinions, \n",
    "    columns=[\"Feature 1 score\", \"Feature 2 score\", \"Feature 3 score\"],\n",
    "    index=[f\"Samsung expert {i+1}\" for i in range(10)]\n",
    ")\n",
    "\n",
    "iphone_expert_opinions_df = pd.DataFrame(\n",
    "    iphone_expert_opinions, \n",
    "    columns=[\"Feature 1 score\", \"Feature 2 score\", \"Feature 3 score\"],\n",
    "    index=[f\"iPhone expert {i+1}\" for i in range(10)]\n",
    ")\n",
    "\n",
    "xiaomi_expert_opinions_df = pd.DataFrame(\n",
    "    xiaomi_expert_opinions, \n",
    "    columns=[\"Feature 1 score\", \"Feature 2 score\", \"Feature 3 score\"],\n",
    "    index=[f\"Xiaomi expert {i+1}\" for i in range(10)]\n",
    ")\n",
    "\n",
    "# Displaying the DataFrames\n",
    "print(\"Samsung Experts' Opinions:\")\n",
    "print(samsung_expert_opinions_df)\n",
    "print(\"\\niPhone Experts' Opinions:\")\n",
    "print(iphone_expert_opinions_df)\n",
    "print(\"\\nXiaomi Experts' Opinions:\")\n",
    "print(xiaomi_expert_opinions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the primary modeler's posterior distribution on brands before and after opinion merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure window\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Variable names for the x-ticks\n",
    "variable_names = ['Samsung', 'iPhone', 'Xiaomi']\n",
    "\n",
    "# Plotting the old posterior distribution\n",
    "axes[0].bar(variable_names, primary_modeler_posterior_old)\n",
    "axes[0].set_ylabel('Probability')\n",
    "axes[0].set_title(\"Primary modeler's prior preference\", fontsize=15.5)\n",
    "axes[0].tick_params(axis='x', labelsize=17)\n",
    "\n",
    "# Plotting the updated posterior distribution\n",
    "axes[1].bar(variable_names, primary_modeler_posterior_updated)\n",
    "axes[1].set_ylabel('Probability')\n",
    "axes[1].set_title(\"Primary modeler's posterior preference\", fontsize=15.5)\n",
    "axes[1].tick_params(axis='x', labelsize=17)\n",
    "\n",
    "# Save the figure\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_0.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest that the experts influenced the primary modeler's  opinion to favor the Samsung brand. Additionally, the primary modeler's probability of choosing the Xiaomi brand prior to opinion merging is low due to the low score assigned to feature 3 for the Xiaomi brand.  Consequently, this leads to a low probability entering the posterior distribution before opinion merging, significantly reducing the probability of selecting the Xiaomi brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "\n",
    "apply_certainty = False\n",
    "\n",
    "# Setting up the number of responders for each brand\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\\n\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experts are configured to prefer the brands in the following order:\n",
    "\n",
    " **Samsung $\\approx$ iPhone $\\approx$ Xiaomi**, \n",
    "\n",
    "the scores are set up to similar **<ins>high</ins>** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [6, 5, 6], [5, 5, 5], [6, 5, 5], [5, 5, 6], [6, 6, 6],\n",
    "    [5, 6, 5], [6, 5, 5], [6, 5, 5], [5, 6, 6], [6, 5, 5]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 6, 5], [6, 5, 5], [6, 5, 6], [5, 6, 5], [6, 6, 5],\n",
    "    [6, 5, 6], [6, 6, 6], [6, 5, 6], [5, 6, 5], [6, 6, 6]\n",
    "])\n",
    "\n",
    "# Simulated weights for Xiaomi\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [5, 5, 6], [6, 5, 6], [6, 6, 6], [6, 6, 6], [6, 5, 6],\n",
    "    [6, 5, 5], [6, 5, 6], [5, 5, 6], [6, 6, 5], [5, 6, 5]\n",
    "])\n",
    "\n",
    "# Calling the function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# The primary modelers' updated aposteriori distribution on brands:\n",
    "plt.bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "\n",
    "# Set the names of the variables\n",
    "plt.xticks(fontsize=17)\n",
    "\n",
    "# Show the plot\n",
    "plt.ylabel('Probability')\n",
    "plt.title(\"Primary modeler's posterior preference\", fontsize=18)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_1.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on this result are at the end of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "\n",
    "apply_certainty = False\n",
    "\n",
    "# Setting up the number of responders for each brand\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\\n\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experts are configured to prefer the brands in the following order:\n",
    "\n",
    "**Samsung $\\approx$ iPhone $\\approx$ Xiaomi**, \n",
    "                      \n",
    "the scores are set up to similar **<ins>low</ins>** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [3, 4, 4], [3, 4, 4], [4, 4, 4], [4, 3, 3], [4, 3, 3],\n",
    "    [4, 4, 1], [4, 1, 4], [4, 3, 4], [4, 5, 4], [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [4, 4, 4], [4, 3, 4], [4, 4, 4], [4, 4, 2], [4, 3, 4],\n",
    "    [3, 4, 1], [4, 4, 4], [2, 4, 4], [1, 4, 4], [3, 2, 1]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [4, 4, 4], [4, 4, 4], [3, 5, 4], [4, 4, 4], [2, 1, 4],\n",
    "    [4, 4, 5], [3, 4, 2], [4, 3, 4], [4, 4, 1], [1, 2, 3]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "apply_certainty = False\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "trust_matrix = np.ones((3, 10))\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Calling the function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# The primary modelers' updated aposteriori distribution on brands:\n",
    "plt.bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "\n",
    "# Set the names of the variables\n",
    "plt.xticks(fontsize=17)\n",
    "\n",
    "# Show the plot\n",
    "plt.ylabel('Probability')\n",
    "plt.title(\"Primary modeler's posterior preference\", fontsize=18)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_2.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the last two experiments show only a minor difference in the final brand preference. However, it was expected that the primary modeler's opinion would have a stronger influence, pushing the preference towards the following order: **iPhone > Samsung > Xiaomi**.\n",
    "\n",
    "This is attributed to the fact that each expert's contribution to the updated weight $V_{f_{j,b}}$ has a magnitude of +1, and the primary modeler's contribution is also + 1. The cumulative effect of the experts' contributions diminishes the impact of the primary modeler's opinion.\n",
    "\n",
    "To address this, the magnitude of the primary modeler's weights $n_{f_{1,b}}$ needs to be adjusted to ensure that the primary modeler's opinion is not diminished. Further elaboration on this adjustment will be provided in the section titled 'Inclusion of Opinion Certainty' below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclusion of trust\n",
    "In this section, we are examining the integration of trust $t_{I,E_{i}}$, into each expert's $E_{i}$ opinion.  The previously mentioned issue still exists and will be addressed later.\n",
    "For now, the primary modeler's opinion will be de-emphasized. This approach allows for a more precise demonstration of trust inclusion, free from any bias introduced by the primary modeler's opinion.\n",
    "For simplicity, the setup of the following two experiments is the same as in the first example from the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "We start by configuring low trust values $t_{I,E_{i}}$ for experts reacting to the Samsung brand and high trust values for experts reacting to iPhone and Xiaomi. The expected outcome is that the preferred brand should be iPhone, since it has similar score values provided by the experts' $E_{i}$ as Samsung, with iPhone being slightly less favored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "\n",
    "apply_certainty = False\n",
    "\n",
    "# Setting up the number of responders for each brand\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting up trust in experts opinions\n",
    "trust_matrix = np.array([\n",
    "    [0.8, 0.9, 0.3, 0.7, 0.2, 0.2, 0.3, 0.5, 0.4, 0.9],\n",
    "    [0.9, 0.9, 0.3, 0.3, 0.7, 0.7, 0.9, 0.9, 0.4, 0.4],\n",
    "    [0.9, 0.7, 0.8, 0.8, 0.9, 0.8, 0.7, 0.7, 0.8, 0.9]\n",
    "])\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\\n\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [4, 3, 4], [5, 3, 5], [5, 6, 5], [6, 5, 3], [6, 6, 6], \n",
    "    [5, 6, 5], [6, 6, 5], [6, 3, 4], [4, 5, 4], [6, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "apply_certainty = False\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust in expert opinions\n",
    "trust_matrix = np.array([\n",
    "    [0.8, 0.9, 0.3, 0.7, 0.2, 0.2, 0.3, 0.5, 0.4, 0.9],\n",
    "    [0.9, 0.9, 0.3, 0.3, 0.7, 0.7, 0.9, 0.9, 0.4, 0.4],\n",
    "    [0.9, 0.7, 0.8, 0.8, 0.9, 0.8, 0.7, 0.7, 0.8, 0.9]\n",
    "])\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Calling the function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# The primary modelers' updated aposteriori distribution on brands:\n",
    "plt.bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "\n",
    "# Set the names of the variables\n",
    "plt.xticks(fontsize=17)\n",
    "\n",
    "# Show the plot\n",
    "plt.ylabel('Probability')\n",
    "plt.title(\"Primary modeler's posterior preference\", fontsize=18)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_3.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Setting the trust $t_{I,E_{i}}$ for experts reacting to Samsung and iPhone brands to low values and to high values for Xiaomi. The preferred brand should be Xiaomi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "\n",
    "apply_certainty = False\n",
    "\n",
    "# Setting up the number of responders for each brand\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust values for experts\n",
    "trust_matrix = np.array([\n",
    "    [0.8, 0.9, 0.5, 0.9, 0.2, 0.2, 0.2, 0.5, 0.4, 0.9],\n",
    "    [0.3, 0.3, 0.9, 0.9, 0.5, 0.5, 0.2, 0.2, 0.8, 0.8],\n",
    "    [0.5, 0.7, 0.9, 0.2, 0.9, 0.8, 0.9, 0.7, 0.8, 0.9]\n",
    "])\n",
    "\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\\n\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [4, 3, 4], [5, 3, 5], [5, 6, 5], [6, 5, 3], [6, 6, 6], \n",
    "    [5, 6, 5], [6, 6, 5], [6, 3, 4], [4, 5, 4], [6, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [5, 4, 5],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([1, 1, 1])\n",
    "apply_certainty = False\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting up trust in experts opinions\n",
    "trust_matrix = np.array([\n",
    "    [0.8, 0.9, 0.5, 0.9, 0.2, 0.2, 0.2, 0.5, 0.4, 0.9],\n",
    "    [0.3, 0.3, 0.9, 0.9, 0.5, 0.5, 0.2, 0.2, 0.8, 0.8],\n",
    "    [0.5, 0.7, 0.9, 0.2, 0.9, 0.8, 0.9, 0.7, 0.8, 0.9]\n",
    "])\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Calling the function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Round the updated posterior values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n",
    "\n",
    "# Create a figure window\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# The primary modelers' updated aposteriori distribution on brands:\n",
    "plt.bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "\n",
    "# Set the names of the variables\n",
    "plt.xticks(fontsize=17)\n",
    "\n",
    "# Show the plot\n",
    "plt.ylabel('Probability')\n",
    "plt.title(\"Primary modeler's posterior preference\", fontsize=18)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_4.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trust process works as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclusion of certainty\n",
    "This section aims to provide a solution to the problem of setting the primary modeler's initial weights $n_{f_{1,b}}$ so that the primary modeler's opinion is not diminished, this is described in the first three examples. \n",
    "To better demonstrate the proposed solution, the trust values $t_{I,E_{i}} \\in \\langle 0, 1 \\rangle$ are intentionally excluded. When the trust value is not set, it is equivalent to setting the trust $t_{I,E_{i}}$ to the maximum value of 1.\n",
    "In contrast, in the opposite scenario, the weight increments of the experts are generally $t_{I,E_{i}} \\in \\langle 0, 1 \\rangle$, this effect is linearly combined with the value of opinion certainty $c_{I,b,n}$.\n",
    "A simplified solution was deemed to be sufficient.\n",
    "\n",
    "For simplicity, the setup of the following three examples are the same as in the first example from the first section, apart from the setup of the primary modeler's opinion and opinion certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1:\n",
    "This example illustrates the impact of the opinion certainty $c_{I,b,n}$ on the final brand ordering. Setting maximum opinion certainty $c_{I,b,n}$ = 1 in the primary modeler's low scores for the Samsung brand should lead to the preference for the iPhone as the top brand, Xiaomi being the second most preferred brand.\n",
    "\n",
    "The primary modeler's opinion is configured to prefer the brands in the following order:\n",
    "\n",
    "**iPhone > Xiaomi > Samsung**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [3, 4, 1],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_scores_df = pd.DataFrame(\n",
    "    primary_modeler_scores,\n",
    "    index=[\"Samsung\", \"iPhone\", \"Xiaomi\"],\n",
    "    columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modelers Scores Table:\")\n",
    "print(primary_modeler_scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary modeler's certainty in the opinion $c_{I,b,n}$ for each brand is the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 0.4, 0.1])\n",
    "\n",
    "# Round the values and convert them to percentage strings\n",
    "opinion_certainty_percent = [f\"{round(value * 100, 1)}%\" for value in opinion_certainty_array]\n",
    "\n",
    "# Create a DataFrame\n",
    "opinion_certainty_df = pd.DataFrame(\n",
    "    [opinion_certainty_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Opinion Certainty Table:\")\n",
    "print(opinion_certainty_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply certainty\n",
    "apply_certainty = True\n",
    "\n",
    "# Setting up the number of responders for each brand so that the opinion\n",
    "# certainty can be applied as many times as the responders responded\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Apply Certainty:\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low values of opinion certainty $c_{I,b,n}$ for iPhone and Xiaomi, result in higher influence of the experts' opinion on the opinion of the primary modeler. This can be intuitively interpreted as the primary modeler being more receptive to advice from the experts $E_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [4, 3, 4], [5, 3, 5], [5, 6, 5], [6, 5, 3], [6, 6, 6], \n",
    "    [5, 6, 5], [6, 6, 5], [6, 3, 4], [4, 5, 4], [6, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [3, 4, 1],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([1, 0.4, 0.1])\n",
    "apply_certainty = True\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "trust_matrix = np.ones((3, 10))\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Calling the function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# The primary modelers' old posterior distribution on brands:\n",
    "axs[0].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_old)\n",
    "axs[0].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[0].set_ylabel('Probability')\n",
    "axs[0].set_title(\"Primary modeler's prior preference\", fontsize=15.5)\n",
    "\n",
    "# The primary modelers' updated posterior distribution on brands:\n",
    "axs[1].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "axs[1].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[1].set_ylabel('Probability')\n",
    "axs[1].set_title(\"Primary modeler's posterior preference\", fontsize=15.5)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_5.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opinion certainty process works as intended in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "In this example the maximum opinion certainty $c_{I,b,n}$ = 1 in the primary modeler's low scores for the Samsung and iPhone brand should lead to the preference for the Xiaomi brand.\n",
    "\n",
    "The primary modeler's opinion is configured to prefer the brands in the following order:\n",
    "\n",
    "**Xiaomi > iPhone >  Samsung**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [3, 1, 1],\n",
    "    [2, 3, 1],\n",
    "    [6, 5, 5]\n",
    "])\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_scores_df = pd.DataFrame(\n",
    "    primary_modeler_scores,\n",
    "    index=[\"Samsung\", \"iPhone\", \"Xiaomi\"],\n",
    "    columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modelers Scores Table:\")\n",
    "print(primary_modeler_scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary modelers certainty in the opinion $c_{I,b,n}$ for each brand is the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([0.2, 0.2, 1])\n",
    "\n",
    "# Round the values and convert them to percentage strings\n",
    "opinion_certainty_percent = [f\"{round(value * 100, 1)}%\" for value in opinion_certainty_array]\n",
    "\n",
    "# Create a DataFrame\n",
    "opinion_certainty_df = pd.DataFrame(\n",
    "    [opinion_certainty_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Opinion Certainty Table:\")\n",
    "print(opinion_certainty_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous example, low values of opinion certainty $c_{I,b,n}$ for Samsung and iPhone, result in higher influence of the experts' opinion on the opinion of the primary modeler. This can be intuitively interpreted as the primary modeler being more receptive to advice from the experts $E_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [3, 1, 1],\n",
    "    [2, 3, 1],\n",
    "    [6, 5, 5]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([0.2, 0.2, 1])\n",
    "\n",
    "apply_certainty = True\n",
    "\n",
    "# Setting up the number of responders for each brand so that the opinion\n",
    "# certainty can be applied as many times as the responders responded\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [4, 3, 4], [5, 3, 5], [5, 6, 5], [6, 5, 3], [6, 6, 6], \n",
    "    [5, 6, 5], [6, 6, 5], [6, 3, 4], [4, 5, 4], [6, 4, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [3, 1, 1],\n",
    "    [2, 3, 1],\n",
    "    [6, 5, 5]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([0.2, 0.2, 1])\n",
    "apply_certainty = True\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "trust_matrix = np.ones((3, 10))\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Call the simulated_example function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# The primary modelers' old posterior distribution on brands\n",
    "axs[0].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_old)\n",
    "axs[0].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[0].set_ylabel('Probability')\n",
    "axs[0].set_title(\"Primary modeler's prior preference\", fontsize=15.5)\n",
    "\n",
    "# The primary modelers' updated posterior distribution on brands\n",
    "axs[1].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "axs[1].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[1].set_ylabel('Probability')\n",
    "axs[1].set_title(\"Primary modeler's posterior preference\", fontsize=15.5)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_6.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands after opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opinion certainty process works as intended in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "In this example the maximum opinion certainty $c_{I,b,n}$ = 1 in the primary modeler's lowest scores for Samsung brand should lead to the preference for the iPhone brand.\n",
    "\n",
    "The primary modeler's opinion is configured to prefer the brands in the following order:\n",
    "\n",
    "**iPhone > Xiaomi > Samsung**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [1, 1, 1],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_scores_df = pd.DataFrame(\n",
    "    primary_modeler_scores,\n",
    "    index=[\"Samsung\", \"iPhone\", \"Xiaomi\"],\n",
    "    columns=[\"Feature 1\", \"Feature 2\", \"Feature 3\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modelers Scores Table:\")\n",
    "print(primary_modeler_scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, to simulate an issue with this design, all the experts' opinions for Samsung are deliberately set to the highest scores.\n",
    "\n",
    "The primary modelers certainty in the opinion $c_{I,b,n}$ for each brand is the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 0, 0])\n",
    "\n",
    "# Round the values and convert them to percentage strings\n",
    "opinion_certainty_percent = [f\"{round(value * 100, 1)}%\" for value in opinion_certainty_array]\n",
    "\n",
    "# Create a DataFrame\n",
    "opinion_certainty_df = pd.DataFrame(\n",
    "    [opinion_certainty_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Opinion Certainty Table:\")\n",
    "print(opinion_certainty_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary modelers opinion\n",
    "primary_modeler_scores = np.array([\n",
    "    [1, 1, 1],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "# Setting up the opinion certainty\n",
    "opinion_certainty_array = np.array([1, 0, 0])\n",
    "\n",
    "apply_certainty = True\n",
    "\n",
    "# Setting up the number of responders for each brand so that the opinion\n",
    "# certainty can be applied as many times as the responders responded\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "\n",
    "# Setting trust like this is equivalent to no inclusion of trust\n",
    "trust_matrix = np.ones((3, 10))\n",
    "\n",
    "# Primary modelers score preference for each feature\n",
    "score_preference = np.array([4, 4, 4])\n",
    "\n",
    "# Primary modelers brand preference\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "\n",
    "score_range = 6\n",
    "\n",
    "# The values of exponents in Dirichlet distribution must be non-zero,\n",
    "# setting them to a low value\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Displaying the data for verification\n",
    "print(\"Primary Modelers Scores:\\n\", primary_modeler_scores)\n",
    "print(\"Opinion Certainty:\\n\", opinion_certainty_array)\n",
    "print(\"Apply Certainty:\", apply_certainty)\n",
    "print(\"Number of Responders:\\n\", number_of_responders)\n",
    "print(\"Trust Matrix:\\n\", trust_matrix)\n",
    "print(\"Score Preference:\\n\", score_preference)\n",
    "print(\"Brand Preference (Normalized):\\n\", primary_modeler_brand_pref)\n",
    "print(\"Score Range Size:\\n\", score_range)\n",
    "print(\"Low Weight for Unselected Features:\\n\", initial_feature_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When opinion certainty values $c_{I,b,n}$ for iPhone and Xiaomi are set to zero, it results in the complete influence of the experts' opinions on the primary modeler's own opinion. This can be intuitively interpreted as the primary modeler completely replacing his own opinion with the opinions of the experts $E_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experts for SAMSUNG\n",
    "samsung_expert_opinions = np.array([\n",
    "    [6, 6, 6], [6, 6, 6], [6, 6, 6], [6, 6, 6], [6, 6, 6], \n",
    "    [6, 6, 6], [6, 6, 6], [6, 6, 6], [6, 6, 6], [6, 6, 6]\n",
    "])\n",
    "\n",
    "# Simulated experts for IPHONE\n",
    "iphone_expert_opinions = np.array([\n",
    "    [5, 5, 5], [5, 6, 5], [3, 4, 4], [3, 4, 5], [4, 5, 5], \n",
    "    [5, 6, 4], [6, 6, 6], [5, 6, 6], [4, 3, 4], [4, 6, 3]\n",
    "])\n",
    "\n",
    "# Simulated experts for XIAOMI\n",
    "xiaomi_expert_opinions = np.array([\n",
    "    [3, 4, 3], [3, 3, 4], [4, 3, 4], [3, 3, 3], [5, 4, 3], \n",
    "    [3, 5, 5], [4, 5, 6], [4, 3, 2], [3, 4, 3], [4, 3, 4]\n",
    "])\n",
    "\n",
    "# Data for primary modelers scores and other parameters\n",
    "primary_modeler_scores = np.array([\n",
    "    [1, 1, 1],\n",
    "    [6, 5, 6],\n",
    "    [4, 4, 3]\n",
    "])\n",
    "\n",
    "opinion_certainty_array = np.array([1, 0, 0])\n",
    "apply_certainty = True\n",
    "number_of_responders = np.array([10, 10, 10])\n",
    "trust_matrix = np.ones((3, 10))\n",
    "score_preference = np.array([4, 4, 4])\n",
    "primary_modeler_brand_pref = np.array([2, 2, 2])\n",
    "primary_modeler_brand_pref = primary_modeler_brand_pref / np.sum(primary_modeler_brand_pref)\n",
    "score_range = 6\n",
    "initial_feature_weight = 0.01\n",
    "\n",
    "# Call the simulated_example function with the provided data\n",
    "primary_modeler_posterior_old, primary_modeler_posterior_updated = auxiliary.simulated_example(\n",
    "    primary_modeler_scores, opinion_certainty_array, apply_certainty, number_of_responders, trust_matrix,\n",
    "    score_preference, primary_modeler_brand_pref, score_range, initial_feature_weight,\n",
    "    *samsung_expert_opinions, *iphone_expert_opinions, *xiaomi_expert_opinions\n",
    ")\n",
    "\n",
    "# Create a figure window\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# The primary modelers' old posterior distribution on brands\n",
    "axs[0].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_old)\n",
    "axs[0].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[0].set_ylabel('Probability')\n",
    "axs[0].set_title(\"Primary modeler's prior preference\", fontsize=15.5)\n",
    "\n",
    "# The primary modelers' updated posterior distribution on brands\n",
    "axs[1].bar(['Samsung', 'iPhone', 'Xiaomi'], primary_modeler_posterior_updated)\n",
    "axs[1].set_xticklabels(['Samsung', 'iPhone', 'Xiaomi'], fontsize=17)\n",
    "axs[1].set_ylabel('Probability')\n",
    "axs[1].set_title(\"Primary modeler's posterior preference\", fontsize=15.5)\n",
    "\n",
    "# Save the plot\n",
    "save_path = os.path.join(working_directory, 'Bar_charts', 'figure_7.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>The primary modeler's posterior distribution on brands before opinion merging.</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_old_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_old]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_old_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_old_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Old:\")\n",
    "print(primary_modeler_posterior_old_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary modeler's posterior distribution on brands after opinion merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values and convert them to percentage strings\n",
    "primary_modeler_posterior_updated_percent = [f\"{round(value * 100, 2)}%\" for value in primary_modeler_posterior_updated]\n",
    "\n",
    "# Create a DataFrame\n",
    "primary_modeler_posterior_updated_df = pd.DataFrame(\n",
    "    [primary_modeler_posterior_updated_percent],\n",
    "    columns=[\"Samsung\", \"iPhone\", \"Xiaomi\"]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"The Primary Modeler's Aposterior Updated:\")\n",
    "print(primary_modeler_posterior_updated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, an unexpected outcome occurs due to the way each expert's $E_{i}$ contribution to the updated weight $V_{f_{j,b}}$ and the primary modeler's contribution are configured. In particular:\n",
    "\n",
    " 1. Each expert's contribution to the updated weight $V_{f_{i,b}}$ has a magnitude of +1.\n",
    " 2. The primary modeler's contribution to the updated weight $V_{f_{i,b}}$ is also +1 for each expert, given that opinion certainty $c_{I,b,n}$ is set to the maximum value of 1.\n",
    "\n",
    "As a result, the updated weight becomes $V_{i_{Samsung}}$ = 10 for all $i\\in \\{1,2,3\\}$. This leads to high maximum values for the respective probabilities $P_{I}^{0}(F_{i,Samsung}|Samsung)$ for all $i\\in \\{1,2,3\\}$, of choosing the underlying scores. Consequently, the probabilities entering the final posterior distribution on brands $P_{I}^{0}(F_{1,Samsung}|Samsung)P_{I}^{0}(F_{2,Samsung}|Samsung)P_{I}^{0}(F_{3,Samsung}|Samsung)$ remain high, resulting in the selection of the Samsung brand, contrary to the expected outcome.\n",
    "\n",
    "(What will follow in DP is commentary on a future solution using preference elicitation.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMoCOBoT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
